{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM assignment1: Multiclass SVM 구현(피드백 참고 수정본)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         setosa\n",
      "1         setosa\n",
      "2         setosa\n",
      "3         setosa\n",
      "4         setosa\n",
      "         ...    \n",
      "145    virginica\n",
      "146    virginica\n",
      "147    virginica\n",
      "148    virginica\n",
      "149    virginica\n",
      "Name: species, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#IRIS 데이터 로드\n",
    "iris =  sns.load_dataset('iris') \n",
    "X= iris.iloc[:,:4] #학습할데이터\n",
    "y = iris.iloc[:,-1] #타겟\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scal = StandardScaler() #scaling\n",
    "X = scal.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         setosa\n",
      "1         setosa\n",
      "2         setosa\n",
      "3         setosa\n",
      "4         setosa\n",
      "         ...    \n",
      "145    virginica\n",
      "146    virginica\n",
      "147    virginica\n",
      "148    virginica\n",
      "149    virginica\n",
      "Name: species, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One vs rest\n",
    "클래스가 N개 있으면 모든 Class에 대해 1 : N-1로 binary 분류(이 클래스 인지 아닌지)를 한 다음 투표로 결정! 총 N 개의 Classifier가 필요하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Versus Rest 구현을 위해 class가 0인것과 아닌것을 구분하기위한 machine class가 1인것과 아닌 것을 구분하기 위한 머신 등을 미리만들어줌\n",
    "svm_1 = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
    "svm_2 = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
    "svm_3 = SVC(kernel ='rbf', C = 5, gamma = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #테스트/트레인 데이터로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train) #one hot encoding을 먼저해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0]\n",
      "[-1.12470845 -0.86326953 -0.65281099 -0.50248821 -0.76284323 -0.87465573\n",
      "  1.07709345 -0.99281647  0.47441336 -0.99842743 -0.83989348  0.15633457\n",
      "  0.32871788 -0.97965464 -0.72385083 -0.92638376  1.28322481 -0.56240455\n",
      " -0.72719892 -0.99509775  0.43166724 -0.96451557 -0.82991366 -1.03020581\n",
      " -0.75166835  1.13461335  0.39943974 -1.04194106 -0.93376548 -1.06133798]\n",
      "[ 1.36054602  0.62859488  0.0580828  -0.36987093 -0.25686625 -0.79229874\n",
      " -1.03195247 -0.87132049 -0.77957234  0.99327762 -0.73309581 -0.64607768\n",
      " -0.71843897 -0.80882458  0.47748663  0.69953462 -1.11879121 -0.1870504\n",
      " -0.24458236 -0.99337352 -0.76149141 -0.96812018  0.11310267  1.06892719\n",
      " -0.56749692 -1.05639624 -0.74817515 -1.0537858  -0.89721836  1.17126024]\n",
      "[-1.26277651 -0.77964936 -0.40539105 -0.13070947  0.02643314  0.57365649\n",
      " -1.04443118  0.88027844 -0.69605517 -0.99074328  0.52442024 -0.51171892\n",
      " -0.61157919  0.78148257 -0.75517707 -0.76905925 -1.16380018 -0.25333938\n",
      " -0.0251979   0.98843144 -0.67129528  0.89577306 -0.30363489 -1.03647008\n",
      "  0.31622662 -1.07758405 -0.65251719  1.09632055  0.85541707 -1.11042784]\n"
     ]
    }
   ],
   "source": [
    "svm_1.fit(X_train,y_train.iloc[:,0]) # 데이터 클레스가 0인 애인지 아닌지 구분해주는 머신\n",
    "svm_2.fit(X_train,y_train.iloc[:,1]) # 데이터 클레스가 1인 애인지 아닌지 구분해주는 머신\n",
    "svm_3.fit(X_train,y_train.iloc[:,2]) # 데이터 클레스가 2인 애인지 아닌지 구분해주는 머신\n",
    "print(svm_1.predict(X_test)) #데이터 클래스가 0인지 아닌지 구분해주는 애를 통해서 테스트데이터의 클래스가 0인지 0이 아닌인지 예측해보자\n",
    "\n",
    "print(svm_1.decision_function(X_test)) #decision_function hyperplane과의 거리를 구하는 방법 필요하다면 활용해주세요\n",
    "print(svm_2.decision_function(X_test))\n",
    "print(svm_3.decision_function(X_test))\n",
    "#svm1,2,3 모두 decision_function -hyperplane으로부터 얼마나 떨어져 있는지를 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "17\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# 부호가 모든 같은 경우가 있는가? 요모두 동점인 경우가 생길것이다.\n",
    "for i in range(len(X_test)):\n",
    "    # ~. decision_function을 이용하면 해당 데이터가 하이퍼플레인으로부터 얼마나 떨어져있는 지 거리가 나온다 다음은 그 값의 부호를 이용해\n",
    "    # 모두가 동점인 경우가 있는지 출력하는 함수 \n",
    "    if ((np.sign(svm_1.decision_function(X_test)[i]) == np.sign(svm_2.decision_function(X_test)[i]))\n",
    "    and (np.sign(svm_2.decision_function(X_test)[i]) == np.sign(svm_3.decision_function(X_test)[i]))):\n",
    "        print(i)\n",
    "        \n",
    "#먼저 decision_function 이용해 해당 데이터가 하이퍼플레인으로부터 얼마나 떨어져 있는지 부호가 동일한 경우 동점이라고 보고\n",
    "#모두가 동점인 경우는 따로 생각해서 판단해야하므로 먼저 몇번에 있는지 구합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#세개를 봐서 0보다 큰거를 선택함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#앞서 확인한 모두가 동점인 경우를 먼저 확인했으니 for문 돌릴때 먼저 if문으로 확인하고 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "피드백 참고해서 모든 경우 생각해서 수정했습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['versicolor' 'versicolor' 'versicolor' 'virginica' 'virginica'\n",
      " 'virginica' 'setosa' 'virginica' 'setosa' 'versicolor' 'virginica'\n",
      " 'setosa' 'setosa' 'virginica' 'versicolor' 'versicolor' 'setosa'\n",
      " 'versicolor' 'virginica' 'virginica' 'setosa' 'virginica' 'versicolor'\n",
      " 'versicolor' 'virginica' 'setosa' 'setosa' 'virginica' 'virginica'\n",
      " 'versicolor']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Case 1 : One vs Rest SVM을 이부분에 구현해주세요 위 결과들을 이용해서 multi class SVM을 직접 구현해주세요! 하드코딩이 하시기 편할겁니다.\n",
    "\n",
    "y_pred2=[]\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    #동점(모두 양수)인 경우에는 절대값을 사용하여 가장 큰 값을 그 값으로 결정하도록 함(TTT일때)\n",
    "    if (np.sign(svm_1.decision_function(X_test)[i]) > 0 ) and (np.sign(svm_2.decision_function(X_test)[i]) > 0) and (np.sign(svm_3.decision_function(X_test)[i]) > 0):\n",
    "        if (abs(svm_1.decision_function(X_test)[i]) > abs(svm_2.decision_function(X_test)[i])) and (abs(svm_1.decision_function(X_test)[i]) > abs(svm_3.decision_function(X_test)[i])):\n",
    "            y_pred2 =np.append(y_pred2,['setosa'])\n",
    "        elif (abs(svm_2.decision_function(X_test)[i]) > abs(svm_1.decision_function(X_test)[i])) and (abs(svm_2.decision_function(X_test)[i]) > abs(svm_3.decision_function(X_test)[i])):\n",
    "            y_pred2 =np.append(y_pred2,['versicolor'])\n",
    "        elif (abs(svm_3.decision_function(X_test)[i]) > abs(svm_1.decision_function(X_test)[i])) and (abs(svm_3.decision_function(X_test)[i]) > abs(svm_2.decision_function(X_test)[i])):\n",
    "            y_pred2 =np.append(y_pred2,['virginica'])\n",
    "    #동점(모두 음수)인 경우에는 절대값을 사용하여 더 적은(거리가 짧은) 값으로 결정하도록 함(FFF일때)\n",
    "    elif (np.sign(svm_1.decision_function(X_test)[i]) < 0 ) and (np.sign(svm_2.decision_function(X_test)[i]) < 0) and (np.sign(svm_3.decision_function(X_test)[i]) < 0):\n",
    "        if (abs(svm_1.decision_function(X_test)[i]) < abs(svm_2.decision_function(X_test)[i])) and (abs(svm_1.decision_function(X_test)[i]) < abs(svm_3.decision_function(X_test)[i])):\n",
    "            y_pred2 =np.append(y_pred2,['setosa'])\n",
    "        elif (abs(svm_2.decision_function(X_test)[i]) < abs(svm_1.decision_function(X_test)[i])) and (abs(svm_2.decision_function(X_test)[i]) < abs(svm_3.decision_function(X_test)[i])):\n",
    "            y_pred2 =np.append(y_pred2,['versicolor'])\n",
    "        elif (abs(svm_3.decision_function(X_test)[i]) < abs(svm_1.decision_function(X_test)[i])) and (abs(svm_3.decision_function(X_test)[i]) < abs(svm_2.decision_function(X_test)[i])):\n",
    "            y_pred2 =np.append(y_pred2,['virginica'])    \n",
    "    #두개는 True, 하나는 False인 경우. 두 True중 큰 값으로 그 결과를 선택하도록함\n",
    "    #(TTF일때)\n",
    "    elif (np.sign(svm_1.decision_function(X_test)[i]) > 0 ) and (np.sign(svm_2.decision_function(X_test)[i]) > 0) and (np.sign(svm_3.decision_function(X_test)[i]) < 0):\n",
    "        if svm_1.decision_function(X_test[i]) > svm_1.decision_function(X_test[i]):\n",
    "            y_pred2 = np.append(y_pred2,['setosa'])\n",
    "        else:\n",
    "            y_pred2 = np.append(y_pred2,['versicolor'])\n",
    "    #(TFT일때)\n",
    "    elif (np.sign(svm_1.decision_function(X_test)[i]) > 0 ) and (np.sign(svm_2.decision_function(X_test)[i]) < 0) and (np.sign(svm_3.decision_function(X_test)[i]) > 0):\n",
    "        if svm_1.decision_function(X_test[i]) > svm_3.decision_function(X_test[i]):\n",
    "            y_pred2 = np.append(y_pred2,['setosa'])\n",
    "        else:\n",
    "            y_pred2 = np.append(y_pred2,['virginica'])\n",
    "    #(FTT일때)\n",
    "    elif (np.sign(svm_1.decision_function(X_test)[i]) < 0 ) and (np.sign(svm_2.decision_function(X_test)[i]) > 0) and (np.sign(svm_3.decision_function(X_test)[i]) > 0):\n",
    "        if svm_2.decision_function(X_test[i]) > svm_3.decision_function(X_test[i]):\n",
    "            y_pred2 = np.append(y_pred2,['versicolor'])\n",
    "        else:\n",
    "            y_pred2 = np.append(y_pred2,['virginica'])\n",
    "                \n",
    "    #동점이 아닌경우(하나만 True인 경우)에는 한 값만이 양수일테니 양수인 값을통해 결정하도록 함\n",
    "    elif (np.sign(svm_1.decision_function(X_test)[i]) > 0 ):\n",
    "        y_pred2 =np.append(y_pred2,['setosa'])\n",
    "    elif (np.sign(svm_2.decision_function(X_test)[i]) > 0):\n",
    "            y_pred2 =np.append(y_pred2,['versicolor'])\n",
    "    elif (np.sign(svm_3.decision_function(X_test)[i]) > 0):\n",
    "        y_pred2 =np.append(y_pred2,['virginica'])\n",
    "print(y_pred2) #multi SVM을 통해 분류한 predict한 값\n",
    "    \n",
    "metrics.accuracy_score(y_test,y_pred2) #0.866667 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그냥 원래 라이브러리가 제공하는 멀티클래스 SVM과 여러분이 구현한 multiclass SVM결과를 한 번 비교해주세요\n",
    "from sklearn.model_selection import train_test_split #데이터셋 분리\n",
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X, y, test_size=0.2, random_state=48)\n",
    "\n",
    "\n",
    "svm_4 = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
    "svm_4.fit(X_train_2, y_train_2)\n",
    "y_pred = svm_4.predict(X_test_2)\n",
    "\n",
    "metrics.accuracy_score(y_test_2,y_pred) #0.83333 나옵니다\n",
    "\n",
    "#결과적으로 라이브러리로 구현한 svm보다 제가 구현한 svm이 더 성능이 좋은 것 같네요..!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
